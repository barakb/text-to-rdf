# Ollama Local LLM Configuration
# Copy this to .env to use local Ollama models

# Setup:
# 1. Install Ollama: https://ollama.ai
# 2. Start Ollama: ollama serve
# 3. Pull model: ollama pull qwen2.5:7b

# API key (use "ollama" for local models)
GENAI_API_KEY=ollama

# RDF Extraction Model: The LLM used for entity and relation extraction
# For Ollama, use just the model name (no "ollama:" prefix needed)
# Default: qwen2.5:7b (Best 7B model for document-level extraction - 40% F1)
RDF_EXTRACTION_MODEL=qwen2.5:7b

# Temperature (0.0 = deterministic, 1.0 = creative)
GENAI_TEMPERATURE=0.3

# Max tokens in response
GENAI_MAX_TOKENS=4096

# Optional: Custom system prompt
# GENAI_SYSTEM_PROMPT="Extract RDF entities as JSON-LD..."

# Ontologies (comma-separated URLs)
# RDF_ONTOLOGIES=https://schema.org/,http://www.w3.org/2006/time#

# ============================================
# Entity Linking Configuration
# ============================================
# Enable entity linking to resolve names to canonical URIs (default: false)
ENTITY_LINKING_ENABLED=true

# Entity linking strategy: dbpedia, wikidata, none
ENTITY_LINKING_STRATEGY=dbpedia

# DBpedia Spotlight service URL
ENTITY_LINKING_SERVICE_URL=https://api.dbpedia-spotlight.org/en

# Minimum confidence threshold for entity linking (0.0-1.0)
ENTITY_LINKING_CONFIDENCE=0.5

# ============================================
# Model Selection Guide (Based on Evaluation)
# ============================================
#
# Tested on DocRED (document-level extraction):
# ✅ qwen2.5:7b    - 39.68% F1 (BEST 7B model - RECOMMENDED)
# ✅ llama3.3:70b  - ~55-65% F1 (Best overall local option)
# ⚠️  mistral      - 26.94% F1 (Relation direction problems)
# ❌ phi4          - 7.41% F1 (Property truncation issues)
# ❌ llama3.1      - 0.00% F1 (Cannot produce valid JSON-LD)
#
# Recommendations:
# - Document-level: qwen2.5:7b (default, best 7B)
# - Sentence-level: llama3.3:8b (good balance)
# - Production: llama3.3:70b (requires 40GB RAM)
# - Quick testing: llama3.2 (fast but less accurate)
#
# RDF_EXTRACTION_MODEL=qwen2.5:7b    # Best 7B (default)
# RDF_EXTRACTION_MODEL=llama3.3:70b  # Best overall (heavy)
# RDF_EXTRACTION_MODEL=llama3.3:8b   # Good for sentence-level
# RDF_EXTRACTION_MODEL=llama3.2      # Quick testing only

